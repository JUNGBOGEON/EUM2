'use client';

import { useState, useCallback, useEffect, useRef } from 'react';
import { useMeetingManager, useAudioInputs } from 'amazon-chime-sdk-component-library-react';
import {
  VoiceFocusDeviceTransformer,
  isAudioTransformDevice,
} from 'amazon-chime-sdk-js';

export interface UseVoiceFocusReturn {
  /** Voice Focus ì§€ì› ì—¬ë¶€ */
  isVoiceFocusSupported: boolean;
  /** Voice Focus í™œì„±í™” ìƒíƒœ */
  isVoiceFocusEnabled: boolean;
  /** Voice Focus ë¡œë”© ìƒíƒœ */
  isVoiceFocusLoading: boolean;
  /** Voice Focus í† ê¸€ */
  toggleVoiceFocus: () => Promise<void>;
}

/**
 * Voice Focus (ë…¸ì´ì¦ˆ ì–µì œ) ê¸°ëŠ¥ì„ ê´€ë¦¬í•˜ëŠ” hook
 *
 * - ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ë°°ê²½ ì†ŒìŒ ì œê±°
 * - ê¸°ë³¸ê°’: í™œì„±í™” (enabled by default)
 * - ì§€ì›ë˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì—ì„œëŠ” ìë™ ë¹„í™œì„±í™”
 */
export function useVoiceFocus(): UseVoiceFocusReturn {
  const meetingManager = useMeetingManager();
  const { selectedDevice } = useAudioInputs();

  // ì´ˆê¸°ê°’ì„ trueë¡œ ì„¤ì • (ì§€ì› ì—¬ë¶€ í™•ì¸ í›„ ë³€ê²½)
  const [isVoiceFocusSupported, setIsVoiceFocusSupported] = useState(true);
  const [isVoiceFocusEnabled, setIsVoiceFocusEnabled] = useState(false);
  const [isVoiceFocusLoading, setIsVoiceFocusLoading] = useState(false);

  const voiceFocusTransformerRef = useRef<VoiceFocusDeviceTransformer | null>(null);
  const originalDeviceRef = useRef<string | null>(null);
  const hasInitializedRef = useRef(false);
  const isCheckingSupportRef = useRef(false);

  // Voice Focus ì§€ì› ì—¬ë¶€ í™•ì¸ ë° ì´ˆê¸°í™”
  useEffect(() => {
    if (isCheckingSupportRef.current) return;
    isCheckingSupportRef.current = true;

    const checkSupport = async () => {
      try {
        console.log('[VoiceFocus] Checking browser support...');
        const isSupported = await VoiceFocusDeviceTransformer.isSupported();
        setIsVoiceFocusSupported(isSupported);

        if (isSupported) {
          console.log('[VoiceFocus] âœ… Supported in this browser');
        } else {
          console.log('[VoiceFocus] âŒ Not supported in this browser');
        }
      } catch (error) {
        console.error('[VoiceFocus] Error checking support:', error);
        setIsVoiceFocusSupported(false);
      }
    };

    checkSupport();
  }, []);

  // Voice Focus transformer ì´ˆê¸°í™”
  const initializeVoiceFocus = useCallback(async (): Promise<VoiceFocusDeviceTransformer | null> => {
    if (voiceFocusTransformerRef.current) {
      console.log('[VoiceFocus] Using cached transformer');
      return voiceFocusTransformerRef.current;
    }

    try {
      console.log('[VoiceFocus] Creating transformer...');
      const transformer = await VoiceFocusDeviceTransformer.create();
      voiceFocusTransformerRef.current = transformer;
      console.log('[VoiceFocus] âœ… Transformer created successfully');
      return transformer;
    } catch (error) {
      console.error('[VoiceFocus] âŒ Failed to create transformer:', error);
      return null;
    }
  }, []);

  // Voice Focus í™œì„±í™”
  const enableVoiceFocus = useCallback(async () => {
    console.log('[VoiceFocus] Attempting to enable...');
    console.log('[VoiceFocus] - isVoiceFocusSupported:', isVoiceFocusSupported);
    console.log('[VoiceFocus] - audioVideo ready:', !!meetingManager.audioVideo);

    if (!isVoiceFocusSupported) {
      console.log('[VoiceFocus] âŒ Not supported, skipping enable');
      return;
    }

    const audioVideo = meetingManager.audioVideo;
    if (!audioVideo) {
      console.log('[VoiceFocus] âŒ AudioVideo not ready, skipping enable');
      return;
    }

    setIsVoiceFocusLoading(true);
    console.log('[VoiceFocus] ğŸ”„ Loading started...');

    try {
      const transformer = await initializeVoiceFocus();
      if (!transformer) {
        throw new Error('Failed to initialize Voice Focus transformer');
      }

      // í˜„ì¬ ì¥ì¹˜ ì €ì¥
      const currentDevice = selectedDevice;
      if (currentDevice && typeof currentDevice === 'string') {
        originalDeviceRef.current = currentDevice;
        console.log('[VoiceFocus] Original device saved:', currentDevice);
      }

      // Voice Focus ì¥ì¹˜ ìƒì„±
      const deviceToTransform = originalDeviceRef.current || 'default';
      console.log('[VoiceFocus] Creating transform device for:', deviceToTransform);

      const voiceFocusDevice = await transformer.createTransformDevice(deviceToTransform);

      if (voiceFocusDevice) {
        console.log('[VoiceFocus] Transform device created, applying...');
        await meetingManager.startAudioInputDevice(voiceFocusDevice);
        setIsVoiceFocusEnabled(true);
        console.log('[VoiceFocus] âœ… Enabled successfully!');
      } else {
        throw new Error('Failed to create Voice Focus device');
      }
    } catch (error) {
      console.error('[VoiceFocus] âŒ Failed to enable:', error);
      setIsVoiceFocusEnabled(false);
    } finally {
      setIsVoiceFocusLoading(false);
      console.log('[VoiceFocus] ğŸ”„ Loading finished');
    }
  }, [isVoiceFocusSupported, meetingManager, selectedDevice, initializeVoiceFocus]);

  // Voice Focus ë¹„í™œì„±í™”
  const disableVoiceFocus = useCallback(async () => {
    console.log('[VoiceFocus] Attempting to disable...');

    const audioVideo = meetingManager.audioVideo;
    if (!audioVideo) {
      console.log('[VoiceFocus] âŒ AudioVideo not ready');
      return;
    }

    setIsVoiceFocusLoading(true);
    console.log('[VoiceFocus] ğŸ”„ Loading started...');

    try {
      // ì›ë³¸ ì¥ì¹˜ë¡œ ë³µì›
      const originalDevice = originalDeviceRef.current || 'default';
      console.log('[VoiceFocus] Restoring original device:', originalDevice);
      await meetingManager.startAudioInputDevice(originalDevice);
      setIsVoiceFocusEnabled(false);
      console.log('[VoiceFocus] âœ… Disabled successfully!');
    } catch (error) {
      console.error('[VoiceFocus] âŒ Failed to disable:', error);
    } finally {
      setIsVoiceFocusLoading(false);
      console.log('[VoiceFocus] ğŸ”„ Loading finished');
    }
  }, [meetingManager]);

  // Voice Focus í† ê¸€
  const toggleVoiceFocus = useCallback(async () => {
    console.log('[VoiceFocus] Toggle called, current state:', {
      isVoiceFocusEnabled,
      isVoiceFocusLoading,
      isVoiceFocusSupported,
    });

    if (isVoiceFocusLoading) {
      console.log('[VoiceFocus] â³ Already loading, ignoring toggle');
      return;
    }

    if (!isVoiceFocusSupported) {
      console.log('[VoiceFocus] âŒ Not supported, ignoring toggle');
      return;
    }

    if (isVoiceFocusEnabled) {
      await disableVoiceFocus();
    } else {
      await enableVoiceFocus();
    }
  }, [isVoiceFocusEnabled, isVoiceFocusLoading, isVoiceFocusSupported, enableVoiceFocus, disableVoiceFocus]);

  // ê¸°ë³¸ í™œì„±í™”: ë¯¸íŒ… ì°¸ê°€ í›„ ìë™ìœ¼ë¡œ Voice Focus í™œì„±í™”
  useEffect(() => {
    const audioVideo = meetingManager.audioVideo;

    // audioVideoê°€ ì¤€ë¹„ë˜ê³ , ì•„ì§ ì´ˆê¸°í™”í•˜ì§€ ì•Šì•˜ê³ , ì§€ì›ë˜ëŠ” ê²½ìš°
    if (audioVideo && !hasInitializedRef.current && isVoiceFocusSupported) {
      hasInitializedRef.current = true;
      console.log('[VoiceFocus] ğŸš€ Auto-enabling Voice Focus in 1 second...');

      // ì•½ê°„ì˜ ë”œë ˆì´ í›„ í™œì„±í™” (ì˜¤ë””ì˜¤ ì¥ì¹˜ ì„¤ì • ì™„ë£Œ ëŒ€ê¸°)
      const timer = setTimeout(() => {
        enableVoiceFocus();
      }, 1000);

      return () => clearTimeout(timer);
    }
  }, [meetingManager.audioVideo, isVoiceFocusSupported, enableVoiceFocus]);

  // í´ë¦°ì—…
  useEffect(() => {
    return () => {
      if (voiceFocusTransformerRef.current) {
        console.log('[VoiceFocus] Cleaning up transformer');
        voiceFocusTransformerRef.current = null;
      }
    };
  }, []);

  return {
    isVoiceFocusSupported,
    isVoiceFocusEnabled,
    isVoiceFocusLoading,
    toggleVoiceFocus,
  };
}
