'use client';

import { useState, useCallback, useEffect, useRef } from 'react';
import { useParams, useRouter } from 'next/navigation';
import {
  MeetingProvider,
  useMeetingManager,
  useLocalVideo,
  useToggleLocalMute,
  useContentShareControls,
  useContentShareState,
  useRosterState,
  useRemoteVideoTileState,
  lightTheme,
} from 'amazon-chime-sdk-component-library-react';
import { ThemeProvider } from 'styled-components';
import WhiteboardCanvas from '@/components/whiteboard/WhiteboardCanvas'; // í™”ì´íŠ¸ë³´ë“œ import ì¶”ê°€
// Custom hooks
import {
  useDeviceManager,
  useBrowserTranscription,
  useMeetingConnection,
  useTranslation,
  useVoiceFocus,
  useTranscriptSync,
  useTTS,
  useMediaDelay,
  useOriginalAudioVolume,
  useMeetingChat,
  useParticipantVolume,
  DEFAULT_MEDIA_DELAY_CONFIG,
} from '@/hooks/meeting';
import type { SessionEndedPayload } from '@/hooks/meeting';
import { useVoiceEnrollment } from '@/hooks/useVoiceEnrollment';
// New modular components (Main ë¸Œëœì¹˜ì˜ ì»´í¬ë„ŒíŠ¸ë“¤)
import {
  MeetingHeader,
  MeetingControls,
  VideoGrid,
  CommunicationPanel,
  DeviceSettingsDialog,
  FloatingSubtitle,
  EndMeetingDialog,
  TTSSettingsDialog,
  SessionEndedModal,
} from './_components';
// Legacy components for loading/error states
import {
  LoadingView,
  ErrorView,
  PermissionBanner,
} from '@/components/meeting';

// Types
import type { ChimeRosterAttendee } from '@/lib/types';

function MeetingRoomContent() {
  const params = useParams();
  const router = useRouter();
  const meetingManager = useMeetingManager();
  const workspaceId = params.id as string;
  const meetingId = params.meetingId as string;

  const [showDeviceSettings, setShowDeviceSettings] = useState(false);
  const [showEndMeetingDialog, setShowEndMeetingDialog] = useState(false);
  const [showWhiteboard, setShowWhiteboard] = useState(false); // í™”ì´íŠ¸ë³´ë“œ ìƒíƒœ ì¶”ê°€
  const [showTTSSettings, setShowTTSSettings] = useState(false); // TTS ì„¤ì • ë‹¤ì´ì–¼ë¡œê·¸
  const [muteOriginalOnTranslation, setMuteOriginalOnTranslation] = useState(true); // ë²ˆì—­ ì‹œ ì›ë³¸ ìŒì„± ìŒì†Œê±° (ê¸°ë³¸: ON)
  
  // ì„¸ì…˜ ì¢…ë£Œ ëª¨ë‹¬ ìƒíƒœ (í˜¸ìŠ¤íŠ¸ê°€ íšŒì˜ë¥¼ ì¢…ë£Œí–ˆì„ ë•Œ)
  const [showSessionEndedModal, setShowSessionEndedModal] = useState(false);
  const [sessionEndedPayload, setSessionEndedPayload] = useState<SessionEndedPayload | null>(null);

  // Voice dubbing state (ë‚´ ëª©ì†Œë¦¬ TTS)
  const [hasVoiceEmbedding, setHasVoiceEmbedding] = useState(false);
  const [voiceDubbingEnabled, setVoiceDubbingEnabled] = useState(false);
  const [isTogglingVoiceDubbing, setIsTogglingVoiceDubbing] = useState(false);
  const { getVoiceStatus, toggleVoiceDubbing } = useVoiceEnrollment();

  // Fetch voice status on mount
  useEffect(() => {
    const fetchVoiceStatus = async () => {
      try {
        const status = await getVoiceStatus();
        setHasVoiceEmbedding(status.hasVoiceEmbedding);
        setVoiceDubbingEnabled(status.voiceDubbingEnabled);
      } catch (err) {
        console.warn('[MeetingPage] Failed to fetch voice status:', err);
      }
    };
    fetchVoiceStatus();
  }, [getVoiceStatus]);

  // Handle voice dubbing toggle
  const handleToggleVoiceDubbing = useCallback(async (enabled: boolean) => {
    setIsTogglingVoiceDubbing(true);
    try {
      const result = await toggleVoiceDubbing(enabled);
      setVoiceDubbingEnabled(result.voiceDubbingEnabled);
    } catch (err) {
      console.error('[MeetingPage] Failed to toggle voice dubbing:', err);
    } finally {
      setIsTogglingVoiceDubbing(false);
    }
  }, [toggleVoiceDubbing]);

  // Handle mute original audio toggle
  const handleToggleMuteOriginal = useCallback(() => {
    setMuteOriginalOnTranslation(prev => !prev);
  }, []);

  // Debug logging for Whiteboard entry point
  useEffect(() => {
    console.log('[MeetingPage] showWhiteboard state changed:', showWhiteboard);
    console.log('[MeetingPage] meetingId:', meetingId);
  }, [showWhiteboard, meetingId]);

  // stopTranscription ref (useBrowserTranscriptionë³´ë‹¤ ë¨¼ì € ì •ì˜ëœ ì½œë°±ì—ì„œ ì‚¬ìš©)
  const stopTranscriptionRef = useRef<(() => void) | null>(null);
  // Custom hooks
  const {
    devicesInitialized,
    audioInitialized,
    permissionError,
    videoDevices,
    audioInputDevices,
    selectedVideoDevice,
    selectedAudioDevice,
    selectDevices,
    initializeAudioOnly,
    changeVideoDevice,
    changeAudioDevice,
    clearPermissionError,
  } = useDeviceManager();

  const { meeting, isJoining, error, userId, currentUser, currentAttendeeId, isHost, handleLeave: originalHandleLeave, handleEndMeeting: originalHandleEndMeeting } = useMeetingConnection({
    meetingId,
    workspaceId,
  });

  // íšŒì˜ ì—°ê²° í›„ ì˜¤ë””ì˜¤ ìë™ ì´ˆê¸°í™” (ìŒì†Œê±° ë²„íŠ¼ ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´)
  useEffect(() => {
    if (meeting && !audioInitialized) {
      console.log('[MeetingPage] Auto-initializing audio after meeting connection...');
      initializeAudioOnly();
    }
  }, [meeting, audioInitialized, initializeAudioOnly]);
  // Meeting start time (timestamp) - ensure UTC parsing
  const meetingStartTime = (() => {
    if (!meeting?.startedAt) return null;
    let dateStr = typeof meeting.startedAt === 'string' ? meeting.startedAt : '';
    if (dateStr) {
      if (!dateStr.includes('T')) dateStr = dateStr.replace(' ', 'T');
      if (!dateStr.endsWith('Z') && !dateStr.includes('+')) dateStr += 'Z';
    } else {
      dateStr = new Date(meeting.startedAt).toISOString();
    }
    return new Date(dateStr).getTime();
  })();

  useEffect(() => {
    console.log('[MeetingPage] meetingStartTime debug:', {
      hasMeeting: !!meeting,
      startedAt: meeting?.startedAt,
      meetingStartTime,
      now: Date.now()
    });
  }, [meeting, meetingStartTime]);

  // ì„¸ì…˜ ì¢…ë£Œ ì‹œ í•¸ë“¤ëŸ¬ (í˜¸ìŠ¤íŠ¸ê°€ íšŒì˜ë¥¼ ì¢…ë£Œí–ˆì„ ë•Œ ë‹¤ë¥¸ ì°¸ê°€ìë“¤ì—ê²Œ ëª¨ë‹¬ í‘œì‹œ)
  const handleSessionEnded = useCallback(async (payload: SessionEndedPayload) => {
    console.log('[MeetingPage] ğŸ›‘ Session ended by host:', payload);

    // íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì¤‘ì§€ (ref ì‚¬ìš©)
    try {
      stopTranscriptionRef.current?.();
    } catch (error) {
      console.error('[MeetingPage] Failed to stop transcription:', error);
    }

    // Chime ë¯¸íŒ…ì—ì„œ ë‚˜ê°€ê¸°
    try {
      await meetingManager.leave();
    } catch (error) {
      console.error('[MeetingPage] Failed to leave meeting:', error);
    }

    // ëª¨ë‹¬ í‘œì‹œ (í™•ì¸ ë²„íŠ¼ í´ë¦­ ì‹œ ë¦¬ë‹¤ì´ë ‰íŠ¸)
    setSessionEndedPayload(payload);
    setShowSessionEndedModal(true);
  }, [meetingManager]);

  // ì„¸ì…˜ ì¢…ë£Œ ëª¨ë‹¬ í™•ì¸ í•¸ë“¤ëŸ¬
  const handleSessionEndedConfirm = useCallback(() => {
    setShowSessionEndedModal(false);
    setSessionEndedPayload(null);
    router.push(`/workspaces/${workspaceId}`);
  }, [router, workspaceId]);

  // íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë™ê¸°í™” í›… (ë¡œì»¬ + ì›ê²© íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ í†µí•©)
  const {
    transcripts: syncedTranscripts,
    isRoomJoined,
    addLocalTranscript,
    updateLocalTranscript,
    loadHistory,
  } = useTranscriptSync({
    sessionId: meetingId,
    currentUserId: userId,
    currentAttendeeId,
    onSessionEnded: handleSessionEnded,
  });

  // Meeting Chat hook
  const { messages: chatMessages, sendMessage } = useMeetingChat({
    meetingId,
    currentUser: currentUser || undefined,
    meetingStartTime,
  });

  // Debug currentUser in Page
  useEffect(() => {
    console.log('[MeetingPage] User/Chat Debug:', {
      userId,
      hasCurrentUser: !!currentUser,
      currentUserName: currentUser?.name,
      chatMessagesLength: chatMessages.length
    });
  }, [userId, currentUser, chatMessages]);

  // Chime SDK hooks (ìŒì†Œê±° ìƒíƒœ ë¨¼ì € ê°€ì ¸ì˜¤ê¸°)
  const { muted, toggleMute } = useToggleLocalMute();

  // Browser Transcription (í´ë¼ì´ì–¸íŠ¸ ì§ì ‘ AWS Transcribe ì—°ê²°)
  const {
    isStreaming: isTranscribing,
    isLoadingHistory,
    transcriptContainerRef,
    selectedLanguage,
    isChangingLanguage,
    setSelectedLanguage,
    getParticipantByAttendeeId,
    stopTranscription,
  } = useBrowserTranscription({
    sessionId: meetingId,
    meetingStartTime,
    currentUserName: currentUser?.name,
    currentUserProfileImage: currentUser?.profileImage,
    currentAttendeeId,
    userId,
    enabled: true, // í•­ìƒ í™œì„±í™”
    isMuted: muted, // Chime ìŒì†Œê±° ìƒíƒœ ì—°ë™
    isRoomJoined, // WebSocket ë£¸ ì°¸ê°€ ì™„ë£Œ í›„ì—ë§Œ íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì‹œì‘
    // ë™ê¸°í™” í›… ì½œë°± ì—°ê²°
    onLocalTranscript: addLocalTranscript,
    onTimestampCorrection: (id, serverTimestamp) => {
      updateLocalTranscript(id, { timestamp: serverTimestamp });
    },
    onHistoryLoaded: loadHistory,
  });

  // stopTranscription ref ì—…ë°ì´íŠ¸ (handleSessionEndedì—ì„œ ì‚¬ìš©)
  useEffect(() => {
    stopTranscriptionRef.current = stopTranscription;
  }, [stopTranscription]);

  // Translation hook
  const {
    translationEnabled,
    isTogglingTranslation,
    toggleTranslation,
    getTranslation,
    recentTranslations,
  } = useTranslation({
    meetingId,
    userId,
  });

  // TTS hook (ë²ˆì—­ëœ ìë§‰ ìŒì„± ì¬ìƒ) - Original Audio Volumeë³´ë‹¤ ë¨¼ì € í˜¸ì¶œ
  const {
    ttsEnabled,
    isTogglingTTS,
    isPlaying: isTTSPlaying,
    volume: ttsVolume,
    queueLength: ttsQueueLength,
    selectedVoices,
    toggleTTS,
    setVolume: setTTSVolume,
    selectVoice,
  } = useTTS({
    meetingId,
    userId,
  });

  // Original Audio Volume hook (ë²ˆì—­ ì‹œ ì›ë³¸ ìŒì„± ë³¼ë¥¨ ì¡°ì ˆ)
  const {
    targetVolume: originalVolume,
    setTargetVolume: setOriginalVolume,
    isFading: isOriginalVolumeFading,
  } = useOriginalAudioVolume({
    translationEnabled,
    muteOriginalOnTranslation,
  });

  // Voice Focus hook (ë…¸ì´ì¦ˆ ì–µì œ - ê¸°ë³¸ í™œì„±í™”)
  const {
    isVoiceFocusSupported,
    isVoiceFocusEnabled,
    isVoiceFocusLoading,
    toggleVoiceFocus,
  } = useVoiceFocus();

  // Media Delay hook (ìë§‰ ì‹±í¬ìš© ì˜ìƒ/ìŒì„± ë”œë ˆì´)
  const {
    delayEnabled,
    delayMs,
    setDelayEnabled,
    setDelayMs,
  } = useMediaDelay({
    config: DEFAULT_MEDIA_DELAY_CONFIG,
  });

  // Participant Volume Control hook (ê°œì¸ë³„ ë³¼ë¥¨ ì¡°ì ˆ)
  const {
    getParticipantVolume,
    setParticipantVolume,
    toggleParticipantMute,
  } = useParticipantVolume({
    meetingId,
  });

  // Chime SDK hooks
  const { isVideoEnabled, toggleVideo } = useLocalVideo();
  // muted, toggleMuteëŠ” ìœ„ì—ì„œ useBrowserTranscription ì „ì— ì„ ì–¸ë¨
  const { toggleContentShare } = useContentShareControls();
  const { isLocalUserSharing } = useContentShareState();
  const { roster } = useRosterState();
  const { tiles: remoteVideoTiles } = useRemoteVideoTileState(); // Mainì˜ hook ì‚¬ìš©
  const participantCount = Object.keys(roster).length;

  // Convert roster to participants array (with proper typing)
  const participants = Object.entries(roster).map(([attendeeId, attendee]) => {
    const info = getParticipantByAttendeeId(attendeeId);
    return {
      id: attendeeId,
      name: info.name || (attendee as any).name || 'Unknown',
      profileImage: info.profileImage,
    };
  });
  // Camera toggle handler (includes permission request)
  const handleToggleVideo = useCallback(async () => {
    if (!devicesInitialized) {
      const success = await selectDevices();
      if (!success) return;
    }
    await toggleVideo();
  }, [devicesInitialized, selectDevices, toggleVideo]);

  // Microphone toggle handler (ì˜¤ë””ì˜¤ë§Œ ì´ˆê¸°í™” - ë¹ ë¥¸ ì‘ë‹µ)
  const handleToggleMute = useCallback(async () => {
    if (!audioInitialized) {
      const success = await initializeAudioOnly();
      if (!success) return;
    }
    toggleMute();
  }, [audioInitialized, initializeAudioOnly, toggleMute]);

  // íšŒì˜ ë‚˜ê°€ê¸° (íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ë¨¼ì € ì¤‘ì§€)
  const handleLeave = useCallback(() => {
    console.log('[MeetingPage] Stopping transcription before leaving...');
    try {
      stopTranscription();
    } catch (error) {
      console.error('[MeetingPage] Failed to stop transcription, proceeding with leave:', error);
    }
    originalHandleLeave();
  }, [stopTranscription, originalHandleLeave]);

  // íšŒì˜ ì¢…ë£Œ ë²„íŠ¼ í´ë¦­ ì‹œ ë‹¤ì´ì–¼ë¡œê·¸ í‘œì‹œ
  const handleEndMeetingClick = useCallback(() => {
    setShowEndMeetingDialog(true);
  }, []);

  // íšŒì˜ ì¢…ë£Œ í™•ì¸ (ë‹¤ì´ì–¼ë¡œê·¸ì—ì„œ í™•ì¸ ë²„íŠ¼ í´ë¦­ ì‹œ)
  const handleEndMeetingConfirm = useCallback((generateSummary: boolean) => {
    console.log('[MeetingPage] Stopping transcription before ending meeting...');
    console.log('[MeetingPage] Generate AI summary:', generateSummary);
    setShowEndMeetingDialog(false);
    try {
      stopTranscription();
    } catch (error) {
      console.error('[MeetingPage] Failed to stop transcription, proceeding with end meeting:', error);
    }
    originalHandleEndMeeting(generateSummary);
  }, [stopTranscription, originalHandleEndMeeting]);
  // Loading state
  if (isJoining) {
    return <LoadingView />;
  }
  // Error state
  if (error) {
    return (
      <ErrorView
        error={error}
        onBack={() => router.push(`/workspaces/${workspaceId}`)}
      />
    );
  }
  return (
    <div className="h-screen flex flex-col bg-[#0f0f0f]">
      {/* Header */}
      <MeetingHeader
        title={meeting?.title || 'í™”ìƒíšŒì˜'}
        participantCount={participantCount}
        participants={participants}
        meetingStartTime={meetingStartTime}
        workspaceId={workspaceId}
      // onEndMeeting={handleEndMeeting} // í•„ìš”í•œ ê²½ìš° ì¶”ê°€
      />
      {/* Permission Banner */}
      {permissionError && (
        <PermissionBanner message={permissionError} onClose={clearPermissionError} />
      )}
      {/* Main Content */}
      <main className="flex-1 flex overflow-hidden relative">
        {/* Video Area or Whiteboard */}
        <div className="flex-1 relative flex flex-col h-full">
          {showWhiteboard ? (
            <div className="absolute inset-0 z-10 bg-white">
              <WhiteboardCanvas
                meetingId={meetingId}
                currentUser={currentUser ? { id: currentUser.id, name: currentUser.name, profileImage: currentUser.profileImage } : undefined}
              />
            </div>
          ) : (
            <VideoGrid
              remoteVideoTiles={remoteVideoTiles}
              isVideoEnabled={isVideoEnabled}
              currentUser={currentUser ? { name: currentUser.name, profileImage: currentUser.profileImage } : undefined}
              participants={participants}
              currentAttendeeId={currentAttendeeId}
              delayEnabled={delayEnabled}
              delayMs={delayMs}
              getParticipantVolume={getParticipantVolume}
              onParticipantVolumeChange={setParticipantVolume}
              onParticipantMuteToggle={toggleParticipantMute}
            />
          )}

          {/* í”Œë¡œíŒ… ìë§‰ ì˜¤ë²„ë ˆì´ (ë²ˆì—­ ON + ìµœê·¼ ë²ˆì—­ì´ ìˆì„ ë•Œë§Œ í‘œì‹œ) - í™”ì´íŠ¸ë³´ë“œ ìœ„ì—ë„ í‘œì‹œ */}
          {translationEnabled && recentTranslations.length > 0 && (
            <FloatingSubtitle
              translations={recentTranslations}
              getParticipantByAttendeeId={getParticipantByAttendeeId}
              isWhiteboardActive={showWhiteboard}
            />
          )}
        </div>
        {/* Unified Communication Panel - Always visible on right */}
        <CommunicationPanel
          transcripts={syncedTranscripts}
          messages={chatMessages}
          isTranscribing={isTranscribing}
          isLoadingHistory={isLoadingHistory}
          selectedLanguage={selectedLanguage}
          isChangingLanguage={isChangingLanguage}
          onLanguageChange={setSelectedLanguage}
          containerRef={transcriptContainerRef}
          getParticipantByAttendeeId={getParticipantByAttendeeId}
          translationEnabled={translationEnabled}
          getTranslation={getTranslation}
          onSendMessage={(content) => sendMessage(content, selectedLanguage)}
          meetingStartTime={meetingStartTime}
        />
      </main>
      {/* Controls */}
      <MeetingControls
        muted={muted}
        isVideoEnabled={isVideoEnabled}
        isLocalUserSharing={isLocalUserSharing}
        isHost={isHost}
        translationEnabled={translationEnabled}
        isTogglingTranslation={isTogglingTranslation}
        isVoiceFocusSupported={isVoiceFocusSupported}
        isVoiceFocusEnabled={isVoiceFocusEnabled}
        isVoiceFocusLoading={isVoiceFocusLoading}
        isWhiteboardEnabled={showWhiteboard}
        // TTS props
        ttsEnabled={ttsEnabled}
        isTogglingTTS={isTogglingTTS}
        isTTSPlaying={isTTSPlaying}
        ttsVolume={ttsVolume}
        ttsQueueLength={ttsQueueLength}
        delayEnabled={delayEnabled}
        delayMs={delayMs}
        onToggleMute={handleToggleMute}
        onToggleVideo={handleToggleVideo}
        onToggleScreenShare={() => toggleContentShare()}
        onToggleTranslation={toggleTranslation}
        onToggleVoiceFocus={toggleVoiceFocus}
        onToggleWhiteboard={() => {
          console.log('[MeetingPage] Toggling whiteboard click. Previous state:', showWhiteboard);
          setShowWhiteboard(!showWhiteboard);
        }}
        onToggleTTS={toggleTTS}
        onToggleDelay={() => setDelayEnabled(!delayEnabled)}
        onDelayMsChange={setDelayMs}
        onSetTTSVolume={setTTSVolume}
        originalVolume={originalVolume}
        isOriginalVolumeFading={isOriginalVolumeFading}
        onSetOriginalVolume={setOriginalVolume}
        muteOriginalOnTranslation={muteOriginalOnTranslation}
        onToggleMuteOriginal={handleToggleMuteOriginal}
        hasVoiceEmbedding={hasVoiceEmbedding}
        voiceDubbingEnabled={voiceDubbingEnabled}
        onOpenTTSSettings={() => setShowTTSSettings(true)}
        onOpenSettings={() => setShowDeviceSettings(true)}
        onLeave={handleLeave}
        onEndMeeting={handleEndMeetingClick}
      />
      {/* Device Settings Dialog */}
      <DeviceSettingsDialog
        isOpen={showDeviceSettings}
        onClose={() => setShowDeviceSettings(false)}
        devicesInitialized={devicesInitialized}
        videoDevices={videoDevices}
        audioInputDevices={audioInputDevices}
        selectedVideoDevice={selectedVideoDevice}
        selectedAudioDevice={selectedAudioDevice}
        onSelectDevices={async () => { await selectDevices(); }}
        onChangeVideoDevice={changeVideoDevice}
        onChangeAudioDevice={changeAudioDevice}
      />

      {/* End Meeting Confirmation Dialog */}
      <EndMeetingDialog
        isOpen={showEndMeetingDialog}
        onClose={() => setShowEndMeetingDialog(false)}
        onConfirm={handleEndMeetingConfirm}
      />

      {/* TTS Settings Dialog */}
      <TTSSettingsDialog
        open={showTTSSettings}
        onOpenChange={setShowTTSSettings}
        selectedVoices={selectedVoices}
        onSelectVoice={selectVoice}
        hasVoiceEmbedding={hasVoiceEmbedding}
        voiceDubbingEnabled={voiceDubbingEnabled}
        isTogglingVoiceDubbing={isTogglingVoiceDubbing}
        onToggleVoiceDubbing={handleToggleVoiceDubbing}
      />

      {/* Session Ended Modal (í˜¸ìŠ¤íŠ¸ê°€ íšŒì˜ë¥¼ ì¢…ë£Œí–ˆì„ ë•Œ ë‹¤ë¥¸ ì°¸ê°€ìë“¤ì—ê²Œ í‘œì‹œ) */}
      <SessionEndedModal
        isOpen={showSessionEndedModal}
        payload={sessionEndedPayload}
        onConfirm={handleSessionEndedConfirm}
      />
    </div>
  );
}
export default function MeetingPage() {
  return (
    <ThemeProvider theme={lightTheme}>
      <MeetingProvider>
        <MeetingRoomContent />
      </MeetingProvider>
    </ThemeProvider>
  );
}